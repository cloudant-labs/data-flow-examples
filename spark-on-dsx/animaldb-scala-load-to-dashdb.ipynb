{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_id: string, _rev: string ... 9 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// This command is an entry point into all functionality in Spark SQL and is necessary to execute SQL queries\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "\n",
    "// Loading data from Cloudant db\n",
    "val cloudantdata = sqlContext.read.format(\"org.apache.bahir.cloudant\").\n",
    "option(\"cloudant.host\", \"education.cloudant.com\").\n",
    "load(\"animaldb\")\n",
    "\n",
    "// Caching df in memory to speed computations\n",
    "// and not to retrieve data from cloudant again\n",
    "cloudantdata.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- _rev: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- diet: string (nullable = true)\n",
      " |-- latin_name: string (nullable = true)\n",
      " |-- max_length: double (nullable = true)\n",
      " |-- max_weight: double (nullable = true)\n",
      " |-- min_length: double (nullable = true)\n",
      " |-- min_weight: double (nullable = true)\n",
      " |-- sortfield: string (nullable = true)\n",
      " |-- wiki_page: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cloudantdata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "// JDBC database connection arguments including DB2 username and password\n",
    "import java.util.Properties\n",
    "val connectionProps = new Properties\n",
    "connectionProps.setProperty(\"user\", \"username\")\n",
    "connectionProps.setProperty(\"password\", \"password\")\n",
    "connectionProps.setProperty(\"driver\", \"com.ibm.db2.jcc.DB2Driver\")\n",
    "\n",
    "val DB2_JDBC_URL = \"jdbc:db2://***:50000/BLUDB\"\n",
    "\n",
    "// Save Spark DataFrame to DB2 Warehouse\n",
    "// Optional: To append/overwrite existing data in table, use mode i.e. newDF.write.mode(SaveMode.Overwrite).jdbc(...)\n",
    "cloudantdata.write.jdbc(DB2_JDBC_URL, \"animaldb\", connectionProps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11 with Spark 2.1",
   "language": "scala",
   "name": "scala-spark21"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
