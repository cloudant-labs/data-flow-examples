{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load crime data from Cloudant to Db2 in Spark\n",
    "\n",
    "This Python notebook loads Cloudant documents into Apache Spark, and then saves the Spark DataFrame into a Db2 table.\n",
    "In this tutorial you will:\n",
    "\n",
    "1. Load the Cloudant data from the `crimes` database\n",
    "2. Save the `properties` column in the Spark DataFrame into Db2 Warehouse on Cloud.\n",
    "3. View the data in the Db2 Warehouse table.\n",
    "\n",
    "\n",
    "## Before you begin \n",
    "\n",
    "These are the services required in your IBM Bluemix account:\n",
    "\n",
    "1. [Apache Spark](https://console.bluemix.net/catalog/services/apache-spark)\n",
    "2. [Db2 Warehouse on Cloud](https://console.bluemix.net/catalog/services/dashdb)\n",
    "\n",
    "Watch the [Getting Started on IBM Cloud](https://developer.ibm.com/clouddataservices/docs/spark/get-started/get-started-in-bluemix/) video to add the IBM Analytics for Apache Spark service to your IBM Cloud account.\n",
    "\n",
    "Note: For `Db2 Warehouse on Cloud` service, you'll need to locate and copy the service credentials.\n",
    "These will be required for saving the Spark data into a Db2 Warehouse table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Cloudant data from the `crimes` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: string, _rev: string, geometry: struct<coordinates:array<double>,type:string>, properties: struct<compnos:string,domestic:boolean,fromdate:bigint,main_crimecode:string,naturecode:string,reptdistrict:string,shooting:boolean,source:string>, type: string]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and initialize SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config('cloudant.host', 'examples.cloudant.com')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load Cloudant documents from 'crimes' into Spark DataFrame\n",
    "cloudantdata = spark.read.format('org.apache.bahir.cloudant').load('crimes')\n",
    "\n",
    "# In case of doing multiple operations on a dataframe (select, filter etc.)\n",
    "# you should persist the dataframe.\n",
    "# Othewise, every operation on the dataframe will load the same data from Cloudant again.\n",
    "# Persisting will also speed up computation.\n",
    "cloudantdata.cache() # persisting in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- _rev: string (nullable = true)\n",
      " |-- geometry: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- properties: struct (nullable = true)\n",
      " |    |-- compnos: string (nullable = true)\n",
      " |    |-- domestic: boolean (nullable = true)\n",
      " |    |-- fromdate: long (nullable = true)\n",
      " |    |-- main_crimecode: string (nullable = true)\n",
      " |    |-- naturecode: string (nullable = true)\n",
      " |    |-- reptdistrict: string (nullable = true)\n",
      " |    |-- shooting: boolean (nullable = true)\n",
      " |    |-- source: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema\n",
    "cloudantdata.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Save the `properties` column in the Spark DataFrame into Db2 Warehouse on Cloud\n",
    "\n",
    "In preparation of saving the `properties` struct, we need to extract each field since Db2 does not support this data type.\n",
    "\n",
    "The cell below will:\n",
    "1. Select only the `properties` column\n",
    "2. Use `withColumn` to extract and create new columns for each field in `properties`\n",
    "2. Drop the original `properties` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "propertiesDF = cloudantdata.select('properties')\\\n",
    ".withColumn('properties.compnos', cloudantdata['properties.compnos'])\\\n",
    ".withColumn('properties.domestic', cloudantdata['properties.domestic'])\\\n",
    ".withColumn('properties.fromdate', cloudantdata['properties.fromdate'])\\\n",
    ".withColumn('properties.main_crimecode', cloudantdata['properties.main_crimecode'])\\\n",
    ".withColumn('properties.naturecode', cloudantdata['properties.naturecode'])\\\n",
    ".withColumn('properties.reptdistrict', cloudantdata['properties.reptdistrict'])\\\n",
    ".withColumn('properties.shooting', cloudantdata['properties.shooting'])\\\n",
    ".withColumn('properties.source', cloudantdata['properties.source'])\\\n",
    ".drop('properties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the modified schema that will be saved to the Db2 Warehouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- properties.compnos: string (nullable = true)\n",
      " |-- properties.domestic: boolean (nullable = true)\n",
      " |-- properties.fromdate: long (nullable = true)\n",
      " |-- properties.main_crimecode: string (nullable = true)\n",
      " |-- properties.naturecode: string (nullable = true)\n",
      " |-- properties.reptdistrict: string (nullable = true)\n",
      " |-- properties.shooting: boolean (nullable = true)\n",
      " |-- properties.source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "propertiesDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to run some Scala logic to configure the JDBC dialect for Db2 correctly. Pixiedust provides us a way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.6</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the custom Db2 dialect (with proper string type mapping) using PixieDust scala bridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala cl=dialect global=true\n",
    "import org.apache.spark.sql.jdbc._\n",
    "import org.apache.spark.sql.types.{StringType, BooleanType, DataType}\n",
    "\n",
    "object db2CustomDialect extends JdbcDialect {\n",
    "    override def canHandle(url: String): Boolean = url.startsWith(\"jdbc:db2\")\n",
    "    override def getJDBCType(dt: DataType): Option[JdbcType] = dt match {\n",
    "            case StringType => Option(JdbcType(\"VARCHAR(50)\", java.sql.Types.VARCHAR))\n",
    "            case BooleanType => Option(JdbcType(\"CHAR(1)\", java.sql.Types.CHAR))\n",
    "            case _ => None\n",
    "    }\n",
    "}\n",
    "JdbcDialects.registerDialect(db2CustomDialect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below persists the modified DataFrame into a Db2 Warehouse table.\n",
    "\n",
    "Replace `db2_jdbc_url`, `user`, and `password` with fields `jdbcurl`, `username`, and `password` from your Db2 Warehouse service credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_properties = {\n",
    "   'user': 'username',\n",
    "   'password': 'password',\n",
    "   'driver': 'com.ibm.db2.jcc.DB2Driver'\n",
    "}\n",
    "\n",
    "db2_jdbc_url = 'jdbc:db2://***:50000/BLUDB'\n",
    "\n",
    "# Save Spark DataFrame to Db2 Warehouse\n",
    "propertiesDF.write.jdbc(db2_jdbc_url, 'crimes_filtered', properties=conn_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. View the data in the Db2 Warehouse table\n",
    "1. In the Bluemix dashboard, go to your Db2 Warehouse on Cloud service.\n",
    "2. On the **Manage** tab, click the **Open** button.\n",
    "3. In the Db2 console, click on the **Explore** tab and select the schema that matches your username.\n",
    "4. Select the `CRIMES_FILTERED` table under the selected schema.\n",
    "5. Click **View Data** and you should see a list of documents.\n",
    "\n",
    "To learn more about Cloudant and work with your own Cloudant database, check out the \n",
    " [Cloudant NoSQL DB IBM Bluemix service](https://console.bluemix.net/catalog/services/cloudant-nosql-db).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
